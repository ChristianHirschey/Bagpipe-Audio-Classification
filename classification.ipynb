{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8917155,"sourceType":"datasetVersion","datasetId":5362787}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-10T01:17:59.423851Z","iopub.execute_input":"2024-07-10T01:17:59.424277Z","iopub.status.idle":"2024-07-10T01:17:59.498873Z","shell.execute_reply.started":"2024-07-10T01:17:59.424246Z","shell.execute_reply":"2024-07-10T01:17:59.497508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"pip install pytube pydub","metadata":{"execution":{"iopub.status.busy":"2024-07-10T01:17:59.501490Z","iopub.execute_input":"2024-07-10T01:17:59.502165Z","iopub.status.idle":"2024-07-10T01:18:17.187801Z","shell.execute_reply.started":"2024-07-10T01:17:59.502115Z","shell.execute_reply":"2024-07-10T01:18:17.186152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt \nimport tensorflow as tf \nimport tensorflow_io as tfio\nfrom pytube import Playlist, YouTube\nfrom pydub import AudioSegment\nimport numpy as np\nimport librosa","metadata":{"execution":{"iopub.status.busy":"2024-07-10T01:18:17.190137Z","iopub.execute_input":"2024-07-10T01:18:17.190549Z","iopub.status.idle":"2024-07-10T01:18:17.621066Z","shell.execute_reply.started":"2024-07-10T01:18:17.190512Z","shell.execute_reply":"2024-07-10T01:18:17.619881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Audio Download Function","metadata":{}},{"cell_type":"code","source":"\"\"\"\ntwofour = Playlist('https://www.youtube.com/watch?v=Q6JDOyDqOFs&list=PLel4r-3d96fa-eKRp7CIW6I6xWFW5-3Dx&pp=iAQB')\n\ntwofour.videos[1].streams.filter(only_audio=True) # get itags for audio\n\nfor video in twofour.videos[0:100]:\n    audio = video.streams.get_by_itag(140) # 140 is higher quality audio itag\n    audio.download(output_path='2-4 March', filename_prefix='2-4 March ')\n    \nstrathspey = Playlist('https://www.youtube.com/watch?v=EvX_Tkv-j-c&list=PLel4r-3d96fZ9w3RAhwhel5ud8YWk4Jre&pp=iAQB')\n\nfor video in strathspey.videos[0:100]:\n    audio = video.streams.get_by_itag(140) # 140 is higher quality audio itag\n    audio.download(output_path='Strathspey', filename_prefix='Strathspey ')\n    \nreel = Playlist('https://www.youtube.com/watch?v=TsM7C4ZYmwY&list=PLel4r-3d96fbxHwtJQuZoOkPWve7J02UJ&pp=iAQB')\n\nfor video in reel.videos[0:150]:\n    audio = video.streams.get_by_itag(140) # 140 is higher quality audio itag\n    audio.download(output_path='Reel', filename_prefix='Reel ')\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-07-10T01:18:17.624833Z","iopub.execute_input":"2024-07-10T01:18:17.625350Z","iopub.status.idle":"2024-07-10T01:18:17.636644Z","shell.execute_reply.started":"2024-07-10T01:18:17.625294Z","shell.execute_reply":"2024-07-10T01:18:17.635366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Data Loading Function","metadata":{}},{"cell_type":"code","source":"m = '/kaggle/input/march-strathspey-and-reel-files/2-4 March Trimmed/2-4 March 24th Guards Brigade at Anzio.mp3'\ns = '/kaggle/input/march-strathspey-and-reel-files/Strathspey Trimmed/Strathspey 3 Strathspeys in the Hoose (Piping 100 Day 48).mp3'\nr = '/kaggle/input/march-strathspey-and-reel-files/Reel Trimmed/Reel A Cup of Tea.mp3'","metadata":{"execution":{"iopub.status.busy":"2024-07-10T01:18:17.638134Z","iopub.execute_input":"2024-07-10T01:18:17.638596Z","iopub.status.idle":"2024-07-10T01:18:17.652830Z","shell.execute_reply.started":"2024-07-10T01:18:17.638563Z","shell.execute_reply":"2024-07-10T01:18:17.651375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define Audio Processing Functions","metadata":{}},{"cell_type":"code","source":"def normalize_audio(audio):\n    max_val = np.max(np.abs(audio))\n    audio_normalized = audio / max_val\n    return audio_normalized\n\ndef load_wav_16k_mono_from_mp3(filename):\n    # Convert MP3 to WAV\n    input_file = filename\n    output_file = \"result.wav\"\n    sound = AudioSegment.from_mp3(input_file)\n    sound.export(output_file, format=\"wav\")\n\n    # Read the WAV file using TensorFlow\n    file_contents = tf.io.read_file(output_file)\n    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n    wav = tf.squeeze(wav, axis=-1)\n    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n\n    # Resample to 16 kHz\n    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n    wav = wav.numpy()\n\n    # Normalize audio\n    wav = normalize_audio(wav)\n\n    # Extract MFCCs\n    mfccs = librosa.feature.mfcc(y=wav, sr=16000, n_mfcc=13)\n\n    return mfccs","metadata":{"execution":{"iopub.status.busy":"2024-07-10T01:18:17.654635Z","iopub.execute_input":"2024-07-10T01:18:17.655123Z","iopub.status.idle":"2024-07-10T01:18:17.669345Z","shell.execute_reply.started":"2024-07-10T01:18:17.655078Z","shell.execute_reply":"2024-07-10T01:18:17.667786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot MFCCs","metadata":{}},{"cell_type":"code","source":"mwave = load_wav_16k_mono_from_mp3(m)\nswave = load_wav_16k_mono_from_mp3(s)\nrwave = load_wav_16k_mono_from_mp3(r)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T01:18:17.671049Z","iopub.execute_input":"2024-07-10T01:18:17.671571Z","iopub.status.idle":"2024-07-10T01:18:47.920540Z","shell.execute_reply.started":"2024-07-10T01:18:17.671534Z","shell.execute_reply":"2024-07-10T01:18:47.918942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nlibrosa.display.specshow(mwave, x_axis='time')\nplt.colorbar()\nplt.title('MFCC')\nplt.xlabel('Time')\nplt.ylabel('MFCC Coefficients')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-10T01:18:47.922341Z","iopub.execute_input":"2024-07-10T01:18:47.923759Z","iopub.status.idle":"2024-07-10T01:18:48.403516Z","shell.execute_reply.started":"2024-07-10T01:18:47.923701Z","shell.execute_reply":"2024-07-10T01:18:48.402282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Tensorflow Datasets","metadata":{}},{"cell_type":"code","source":"MARCH = '/kaggle/input/march-strathspey-and-reel-files/2-4 March Trimmed'\nSTRATHSPEY = '/kaggle/input/march-strathspey-and-reel-files/Strathspey Trimmed'\nREEL = '/kaggle/input/march-strathspey-and-reel-files/Reel Trimmed'","metadata":{"execution":{"iopub.status.busy":"2024-07-10T01:18:48.405142Z","iopub.execute_input":"2024-07-10T01:18:48.405627Z","iopub.status.idle":"2024-07-10T01:18:48.411906Z","shell.execute_reply.started":"2024-07-10T01:18:48.405582Z","shell.execute_reply":"2024-07-10T01:18:48.410685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"march = tf.data.Dataset.list_files(MARCH+'/*.mp3')\nstrath = tf.data.Dataset.list_files(STRATHSPEY+'/*.mp3')\nreel = tf.data.Dataset.list_files(REEL+'/*.mp3')","metadata":{"execution":{"iopub.status.busy":"2024-07-10T01:18:48.416143Z","iopub.execute_input":"2024-07-10T01:18:48.416627Z","iopub.status.idle":"2024-07-10T01:18:48.540808Z","shell.execute_reply.started":"2024-07-10T01:18:48.416590Z","shell.execute_reply":"2024-07-10T01:18:48.539138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Process All Files","metadata":{}},{"cell_type":"code","source":"march_data = []\nstrath_data = []\nreel_data = []\n\nfor file_path in march:\n    mfccs = load_wav_16k_mono_from_mp3(file_path.numpy().decode(\"utf-8\"))\n    march_data.append(mfccs)\n\nfor file_path in strath:\n    mfccs = load_wav_16k_mono_from_mp3(file_path.numpy().decode(\"utf-8\"))\n    strath_data.append(mfccs)\n\nfor file_path in reel:\n    mfccs = load_wav_16k_mono_from_mp3(file_path.numpy().decode(\"utf-8\"))\n    reel_data.append(mfccs)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T01:18:48.542511Z","iopub.execute_input":"2024-07-10T01:18:48.542977Z","iopub.status.idle":"2024-07-10T01:33:07.769899Z","shell.execute_reply.started":"2024-07-10T01:18:48.542941Z","shell.execute_reply":"2024-07-10T01:33:07.768382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pad MFCCs","metadata":{}},{"cell_type":"code","source":"# Find the maximum length of MFCCs across all data\nmax_length = max(max(mfcc.shape[1] for mfcc in march_data),\n                 max(mfcc.shape[1] for mfcc in strath_data),\n                 max(mfcc.shape[1] for mfcc in reel_data))\n\ndef pad_mfccs(mfcc, max_length):\n    # Pad the MFCCs with zeros to match the max_length\n    padded_mfcc = np.pad(mfcc, ((0, 0), (0, max_length - mfcc.shape[1])), 'constant')\n    return padded_mfcc\n\n# Pad all MFCCs to the maximum length\nmarch_data = [pad_mfccs(mfcc, max_length) for mfcc in march_data]\nstrath_data = [pad_mfccs(mfcc, max_length) for mfcc in strath_data]\nreel_data = [pad_mfccs(mfcc, max_length) for mfcc in reel_data]\n\n# Verify all MFCCs are correctly padded\nfor mfcc in march_data + strath_data + reel_data:\n    assert mfcc.shape[1] == max_length, \"Padding error: MFCC lengths are inconsistent\"","metadata":{"execution":{"iopub.status.busy":"2024-07-10T01:33:07.771510Z","iopub.execute_input":"2024-07-10T01:33:07.771983Z","iopub.status.idle":"2024-07-10T01:33:07.834037Z","shell.execute_reply.started":"2024-07-10T01:33:07.771934Z","shell.execute_reply":"2024-07-10T01:33:07.832788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate Tensorflow Datasets","metadata":{}},{"cell_type":"code","source":"def generator(data_list, indices):\n    for index in indices:\n        yield data_list[index]\n\n# Create TensorFlow datasets\ndef create_dataset(data):\n    indices = list(range(len(data)))\n    dataset = tf.data.Dataset.from_generator(\n        generator, \n        args=(data, indices), \n        output_signature=tf.TensorSpec(shape=(13, max_length), dtype=tf.float32)\n    )\n    return dataset\n\nmarch_dataset = create_dataset(march_data)\nstrath_dataset = create_dataset(strath_data)\nreel_dataset = create_dataset(reel_data)\n\nmarches = tf.data.Dataset.zip((march_dataset, tf.data.Dataset.from_tensor_slices(tf.zeros(len(march), dtype=tf.int32))))  # Label march as 0\nstrathspeys = tf.data.Dataset.zip((strath_dataset, tf.data.Dataset.from_tensor_slices(tf.ones(len(strath), dtype=tf.int32))))  # Label strathspey as 1\nreels = tf.data.Dataset.zip((reel_dataset, tf.data.Dataset.from_tensor_slices(tf.ones(len(reel), dtype=tf.int32) * 2)))  # Label reel as 2\n\ndata = marches.concatenate(strathspeys).concatenate(reels)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T01:33:07.835707Z","iopub.execute_input":"2024-07-10T01:33:07.836216Z","iopub.status.idle":"2024-07-10T01:33:16.876515Z","shell.execute_reply.started":"2024-07-10T01:33:07.836171Z","shell.execute_reply":"2024-07-10T01:33:16.875180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split and Label Datasets","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Convert the concatenated dataset to a list of tuples\nall_data_padded = list(data)\n\n# Extract features and labels\nfeatures = [item[0].numpy() for item in all_data_padded]\nlabels = [item[1].numpy() for item in all_data_padded]\n\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(features, labels, train_size=0.65, stratify=labels, random_state=42)\n\n# Convert to TensorFlow datasets\ntrain_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\ntest_data = tf.data.Dataset.from_tensor_slices((X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2024-07-10T03:11:58.402336Z","iopub.execute_input":"2024-07-10T03:11:58.402893Z","iopub.status.idle":"2024-07-10T03:12:07.968925Z","shell.execute_reply.started":"2024-07-10T03:11:58.402850Z","shell.execute_reply":"2024-07-10T03:12:07.967688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.regularizers import l2\nimport numpy as np\n\n# 42=66.7%\nseed = 42\ntf.random.set_seed(seed)\nnp.random.seed(seed)\n\nearly_stopping = EarlyStopping(patience=8, restore_best_weights=True, monitor='val_accuracy')\n\n# Assume X_train, X_test, y_train, y_test are already defined\n# Convert lists to numpy arrays\nX_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\n\n# Add a channel dimension\nX_train = X_train[..., np.newaxis]  # Shape: (num_samples, 13, max_length, 1)\nX_test = X_test[..., np.newaxis]    # Shape: (num_samples, 13, max_length, 1)\n\ninput_shape = (13, max_length, 1)  # Ensure max_length is appropriate for your data\n\nmodel = Sequential([\n    Input(shape=input_shape),\n    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.005)),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    Dropout(0.3),\n\n    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.005)),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    Dropout(0.4),\n\n    Flatten(),\n    Dense(128, activation='relu', kernel_regularizer=l2(0.005)),\n    BatchNormalization(),\n    Dropout(0.5),\n\n    Dense(3, activation='softmax')\n])\n\nmodel.compile(optimizer=Adam(learning_rate=0.0005), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2024-07-10T03:14:08.895867Z","iopub.execute_input":"2024-07-10T03:14:08.897192Z","iopub.status.idle":"2024-07-10T03:24:12.362733Z","shell.execute_reply.started":"2024-07-10T03:14:08.897141Z","shell.execute_reply":"2024-07-10T03:24:12.361414Z"},"trusted":true},"execution_count":null,"outputs":[]}]}